<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Keep Balance</title>
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <!-- Centered title -->
    <h1 class="center-title">Keep Balance</h1>

    <!-- Video element to display the camera feed -->
    <video id="video3" autoplay playsinline></video>

    <!-- Canvas element to render the 3D model -->
    <canvas id="three-canvas"></canvas>

    <!-- Container to display the speech text (currently hidden) -->
    <div id="speech-text" class="speech-text"></div>
    
    <!-- Container to display the instruction text -->
    <div id="instruction-text" class="instruction-text"></div>
    
    <!-- Textbox to prompt the user to click the speaker button -->
    <div id="prompt-text" class="prompt-text">Click the sound button to play the voice prompt</div>
    
    <!-- Loading text for displaying model loading progress -->
    <div id="loading-text" class="loading-text">Loading model... 0%</div>

    <!-- Container for the buttons: Back, Previous, Next, and Speaker -->
    <div id="cameraContainer">
      <div class="button-container">
        <!-- Back button -->
        <button class="button" id="backButton">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M10 19l-7-7 7-7v4h8v6h-8v4z" />
          </svg>
        </button>

        <!-- Previous step button -->
        <button class="button" id="previousButton">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M15 19l-7-7 7-7v14z" />
          </svg>
        </button>

        <!-- Next step button -->
        <button class="button" id="nextButton">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M9 19l7-7-7-7v14z" />
          </svg>
        </button>
        
        <!-- Speaker button (used to play the speech prompt) -->
        <button class="button" id="playSoundButton">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path
              d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-.73-3.37-1.91-4.5l-1.42 1.42C14.2 9.98 14.5 10.96 14.5 12s-.3 2.02-.83 2.58l1.42 1.42c1.18-1.13 1.91-2.73 1.91-4.5zM18.5 12c0-3.04-1.23-5.79-3.22-7.78l-1.42 1.42C15.96 6.79 17 9.3 17 12s-1.04 5.21-2.64 6.36l1.42 1.42C17.27 17.79 18.5 15.04 18.5 12z" />
          </svg>
        </button>
      </div>
    </div>

    <!-- Importing necessary scripts (Three.js, model loader, etc.) -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/libs/fflate.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/FBXLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>
    <script src="keepBalance.js"></script>

    <script type="module">
      // Import the camera management script
      import { startCamera } from "./camera.js";
      // Start the camera feed using the video3 element
      startCamera("video3");

      // Three.js setup
      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      const renderer = new THREE.WebGLRenderer({ canvas: document.getElementById("three-canvas"), alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      camera.position.z = 5;

      // Add a light to the scene
      const light = new THREE.DirectionalLight(0xffffff, 1.8);
      light.position.set(0, 1, 1).normalize();
      scene.add(light);

      // Load FBX model
      const loader = new THREE.FBXLoader();
      loader.load("CanCan.fbx", function (object) {
        // Scale and position the model
        object.scale.set(0.04, 0.04, 0.04);
        object.position.set(-7, -4, -3.5);
        const degreesToRotate = 20; 
        const radiansToRotate = degreesToRotate * (Math.PI / 180); 
        object.rotation.y = radiansToRotate; 
        scene.add(object);
        
        // Update loading progress in the loading text
        const loadingText = document.getElementById("loading-text");

        loader.manager.onProgress = function (item, loaded, total) {
          const percentLoaded = Math.round((loaded / total) * 100);
          loadingText.textContent = `Loading model... ${percentLoaded}%`;
        };

        // Hide the loading text once model is loaded
        loader.manager.onLoad = function () {
          loadingText.style.display = "none";
        };

        // Create an animation mixer and play the animation
        const mixer = new THREE.AnimationMixer(object);
        const action = mixer.clipAction(object.animations[0]);
        action.play();

        // Animation and rendering loop with pause functionality
        let pauseTime = 1.1;  // Set to pause at 1.1 seconds
        let paused = false;   // This parameter is used to determine whether it has been paused

        function animate() {
          requestAnimationFrame(animate);

          // Check that the pause time has been reached and pause the animation
          if (!paused && mixer.time >= pauseTime) {
            mixer.setTime(pauseTime);  // Freeze animation at pause time
            paused = true;  
          }

          // Update the animation without pausing
          if (!paused) {
            mixer.update(0.01); // Continue updating animation if not paused
          }

          renderer.render(scene, camera); // Render the scene with updated animation
        }
        animate(); // Start the animation loop
      });
      
      // Handle window resizing to adjust camera aspect ratio and renderer size
      window.addEventListener("resize", () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });

      // Speech synthesis setup (Web Speech API)
      let voices = [];

      // Initialize available voices for speech synthesis
      function initializeVoices() {
        voices = window.speechSynthesis.getVoices();
      }

      // Update the voice list when available
      window.speechSynthesis.onvoiceschanged = initializeVoices;

      // Function to play a specific speech using speech synthesis
      function speak(text, callback) {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.pitch = 1.2; // Set speech pitch
        utterance.rate = 1;    // Set speech rate
        utterance.volume = 1;  // Set speech volume
        utterance.lang = "en"; // Set speech language to English

        // Choose a specific voice based on the browser being used
        let specificVoice = null;
        if (navigator.userAgent.includes("Chrome")) {
          specificVoice = voices.find((voice) => voice.name === "Google UK English Female");
        } else if (navigator.userAgent.includes("Safari")) {
          specificVoice = voices.find((voice) => voice.name === "Samantha");
        } else if (navigator.userAgent.includes("Edg")) {
          specificVoice = voices.find((voice) => voice.name === "Microsoft Natasha Online (Natural) - English (Australia)");
        } else if (navigator.userAgent.includes("Firefox")) {
          specificVoice = voices.find((voice) => voice.name === "Microsoft Zira Desktop - English (United States)");
        } else {
          specificVoice = voices.find((voice) => voice.gender === "female");
        }

        // Set the selected voice
        if (specificVoice) {
          utterance.voice = specificVoice;
        } else {
          console.warn("Specific voice not found, using default.");
        }

        // Run callback function after speech ends
        utterance.onend = function () {
          if (callback) callback();
        };

        // Play the speech
        window.speechSynthesis.speak(utterance);
      }

      // Predefined welcome speech array
      let welcomeSpeech = [
        "Hello, boys and girls, welcome to keep balance of balance!",
        "Stand far away so you can see your whole body on the screen!",
        "Let's follow the character! Ready?",
        "Keep your balance, hold for 5 seconds! You're doing great!"
      ];

      // Store speech timeout references
      let speechTimeouts = [];

      // Event listener for the speaker button click
      const playSoundButton = document.getElementById("playSoundButton");
      playSoundButton.addEventListener("click", () => {
        // Cancel any ongoing speech playback
        window.speechSynthesis.cancel();
        // Hide the prompt text after the button is clicked
        document.getElementById("prompt-text").style.display = "none";
        // Play the predefined speeches
        playSpeeches();
      });

      // Function to play all the speeches sequentially
      function playSpeeches() {
        clearSpeechTimeouts();

        let index = 0;
        function playNextSpeech() {
          if (index < welcomeSpeech.length) {
            speak(welcomeSpeech[index], () => {
              index++;
              if (index < welcomeSpeech.length) {
                setTimeout(playNextSpeech, 2000); // 2 second delay before next speech
              }
            });
          }
        }
        playNextSpeech();
      }

      // Clear speech timeouts if there are any
      function clearSpeechTimeouts() {
        speechTimeouts.forEach((timeout) => clearTimeout(timeout));
      }

      // Stop speech synthesis when leaving the page
      window.addEventListener("beforeunload", () => {
        clearSpeechTimeouts();
        window.speechSynthesis.cancel();
      });

      // Back button functionality 
      const backButton = document.getElementById("backButton");
      backButton.addEventListener("click", () => {
        window.location.href = "../../prac_bal.html";
      });

      // Previous step button functionality
      const previousButton = document.getElementById("previousButton");
      previousButton.addEventListener("click", () => {
        window.location.href = "../../bal_step2.html";
      });

      // Next step button functionality
      const nextButton = document.getElementById("nextButton");
      nextButton.addEventListener("click", () => {
        window.location.href = "../../bal_full.html";
      });
    </script>
  </body>
</html>
